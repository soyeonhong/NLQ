{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "model_name = 'cross-encoder/ms-marco-MiniLM-L-12-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "idx = 12\n",
    "\n",
    "nlq_list = json.loads(Path(\"/data/soyeonhong/GroundVQA/data/unified/annotations.NLQ_val.json\").read_text())\n",
    "llava_caption = json.loads(Path(f\"/data/soyeonhong/GroundVQA/llava-v1.6-34b/global/0aabdda2-d305-44c8-b085-f018ea62d872.json\").read_text())['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_list = []\n",
    "query_list = []\n",
    "frame_idx_list = []\n",
    "for caption in llava_caption:\n",
    "    frame_idx_list.append(caption[0])\n",
    "    caption_list.append(caption[2])\n",
    "    query_list.append(nlq_list[idx]['question'])\n",
    "    \n",
    "# caption_list[-1] = \"I put the fire gun\"\n",
    "# caption_list[-1]\n",
    "\n",
    "features = tokenizer(query_list, caption_list, max_length= 172, return_tensors='pt', padding='max_length', truncation=True) # 무조건 172 나오게 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many wires did i pick from the floor?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([49, 172, 384])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(**features, return_dict=True, output_hidden_states=True)\n",
    "    print(output.hidden_states[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49, 384])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = model.bert.pooler(output.hidden_states[-1])\n",
    "pool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = torch.mean(output.hidden_states[-1], dim=1)\n",
    "# mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_from_mean = model.classifier(mean)\n",
    "# result_from_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 0: -10.9\n",
      "300, 10: -9.73\n",
      "600, 20: -10.53\n",
      "900, 30: -10.52\n",
      "1200, 40: -10.97\n",
      "1500, 50: -10.76\n",
      "1800, 60: -10.77\n",
      "2100, 70: -9.84\n",
      "2400, 80: -10.83\n",
      "2700, 90: -11.17\n",
      "3000, 100: -11.04\n",
      "3300, 110: -11.22\n",
      "3600, 120: -11.26\n",
      "3900, 130: -9.91\n",
      "4200, 140: -10.41\n",
      "4500, 150: -10.78\n",
      "4800, 160: -10.86\n",
      "5100, 170: -10.74\n",
      "5400, 180: -10.93\n",
      "5700, 190: -10.05\n",
      "6000, 200: -9.7\n",
      "6300, 210: -8.27\n",
      "6600, 220: -10.06\n",
      "6900, 230: -10.55\n",
      "7200, 240: -11.01\n",
      "7500, 250: -10.32\n",
      "7800, 260: -6.2\n",
      "8100, 270: -11.02\n",
      "8400, 280: -10.77\n",
      "8700, 290: -10.88\n",
      "9000, 300: -10.56\n",
      "9300, 310: -10.72\n",
      "9600, 320: -11.07\n",
      "9900, 330: -10.69\n",
      "10200, 340: -11.04\n",
      "10500, 350: -11.22\n",
      "10800, 360: -10.99\n",
      "11100, 370: -11.16\n",
      "11400, 380: -7.62\n",
      "11700, 390: -10.71\n",
      "12000, 400: -4.66\n",
      "12300, 410: -10.18\n",
      "12600, 420: -11.21\n",
      "12900, 430: -11.18\n",
      "13200, 440: -11.21\n",
      "13500, 450: -11.23\n",
      "13800, 460: -11.22\n",
      "14100, 470: -10.79\n",
      "14400, 480: -11.22\n"
     ]
    }
   ],
   "source": [
    "result = model.classifier(pool)\n",
    "\n",
    "for idx, res in enumerate(result):\n",
    "    \n",
    "    print(f\"{idx * 300}, {idx * 10}: {round(res.item(), 2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{query_list[0]}\\n\")\n",
    "for caption, logit in zip(caption_list, output.logits):\n",
    "    print(f\"Logit: {logit.item()}\\n{caption}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list = []\n",
    "for frame_idx, result in zip(frame_idx_list, mean_result):\n",
    "    save_list.append((frame_idx, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(save_list, f\"{nlq_list[0]['sample_id']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load(f\"{nlq_list[0]['sample_id']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0: torch.Size([384])\n",
      "   300: torch.Size([384])\n",
      "   600: torch.Size([384])\n",
      "   900: torch.Size([384])\n",
      "  1200: torch.Size([384])\n",
      "  1500: torch.Size([384])\n",
      "  1800: torch.Size([384])\n",
      "  2100: torch.Size([384])\n",
      "  2400: torch.Size([384])\n",
      "  2700: torch.Size([384])\n",
      "  3000: torch.Size([384])\n",
      "  3300: torch.Size([384])\n",
      "  3600: torch.Size([384])\n",
      "  3900: torch.Size([384])\n",
      "  4200: torch.Size([384])\n",
      "  4500: torch.Size([384])\n",
      "  4800: torch.Size([384])\n",
      "  5100: torch.Size([384])\n",
      "  5400: torch.Size([384])\n",
      "  5700: torch.Size([384])\n",
      "  6000: torch.Size([384])\n",
      "  6300: torch.Size([384])\n",
      "  6600: torch.Size([384])\n",
      "  6900: torch.Size([384])\n",
      "  7200: torch.Size([384])\n",
      "  7500: torch.Size([384])\n",
      "  7800: torch.Size([384])\n",
      "  8100: torch.Size([384])\n",
      "  8400: torch.Size([384])\n",
      "  8700: torch.Size([384])\n",
      "  9000: torch.Size([384])\n",
      "  9300: torch.Size([384])\n",
      "  9600: torch.Size([384])\n",
      "  9900: torch.Size([384])\n",
      " 10200: torch.Size([384])\n",
      " 10500: torch.Size([384])\n",
      " 10800: torch.Size([384])\n",
      " 11100: torch.Size([384])\n",
      " 11400: torch.Size([384])\n",
      " 11700: torch.Size([384])\n",
      " 12000: torch.Size([384])\n",
      " 12300: torch.Size([384])\n",
      " 12600: torch.Size([384])\n",
      " 12900: torch.Size([384])\n",
      " 13200: torch.Size([384])\n",
      " 13500: torch.Size([384])\n",
      " 13800: torch.Size([384])\n",
      " 14100: torch.Size([384])\n",
      " 14400: torch.Size([384])\n"
     ]
    }
   ],
   "source": [
    "for frame_idx, result in x:\n",
    "    print(f\"{frame_idx:6d}: {result.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 101, 102, '[CLS]', '[SEP]')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id, tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.cls_token, tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2073,  2106,  1045,  2404,  1996,  2543,  3282,  1029,   102,\n",
       "          1996,  3746,  3065,  2019,  5992,  5997,  2007,  2536,  6177,  1012,\n",
       "          2045,  2024,  4984, 24742,  1010,  2029,  2024,  2109,  2000,  4047,\n",
       "          2019,  5992,  4984,  2013,  4053,  3303,  2011,  2019,  2058, 11066,\n",
       "          2030,  2460,  4984,  1012,  1996,  5997,  2036,  2038,  1037,  2417,\n",
       "          2422,  2006,  2327,  1010,  2029,  2003,  3497,  2019, 17245,  2005,\n",
       "          2019,  8598,  2030,  5432,  2291,  1012,  2000,  1996,  2157,  1010,\n",
       "          2045,  2003,  1037,  3384, 10535,  6729,  2114,  1996,  2813,  1010,\n",
       "          2029,  2003,  4141,  2109,  2005,  3229,  2075,  3020,  2752,  1010,\n",
       "          2107,  2004, 14832,  2015,  2030, 15753,  1012,  1996,  4292,  3544,\n",
       "          2000,  2022,  2019,  4592,  2686,  1010,  4298,  1037,  9710,  2282,\n",
       "          2030,  1037,  2112,  1997,  1037,  2311,  2073,  5992,  3001,  2024,\n",
       "          7431,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1]])}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_one_set = tokenizer(query_list[0], caption_list[0], max_length= 172, return_tensors='pt', padding=True, truncation=True)\n",
    "feature_one_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0     [CLS]           101 (special token)\n",
      " 1     where           2073\n",
      " 2     did             2106\n",
      " 3     i               1045\n",
      " 4     put             2404\n",
      " 5     the             1996\n",
      " 6     fire            2543\n",
      " 7     gun             3282\n",
      " 8     ?               1029\n",
      " 9     [SEP]           102 (special token)\n",
      "10     the             1996\n",
      "11     image           3746\n",
      "12     shows           3065\n",
      "13     an              2019\n",
      "14     electrical      5992\n",
      "15     panel           5997\n",
      "16     with            2007\n",
      "17     various         2536\n",
      "18     components      6177\n",
      "19     .               1012\n",
      "20     there           2045\n",
      "21     are             2024\n",
      "22     circuit         4984\n",
      "23     breakers        24742\n",
      "24     ,               1010\n",
      "25     which           2029\n",
      "26     are             2024\n",
      "27     used            2109\n",
      "28     to              2000\n",
      "29     protect         4047\n",
      "30     an              2019\n",
      "31     electrical      5992\n",
      "32     circuit         4984\n",
      "33     from            2013\n",
      "34     damage          4053\n",
      "35     caused          3303\n",
      "36     by              2011\n",
      "37     an              2019\n",
      "38     over            2058\n",
      "39     ##load          11066\n",
      "40     or              2030\n",
      "41     short           2460\n",
      "42     circuit         4984\n",
      "43     .               1012\n",
      "44     the             1996\n",
      "45     panel           5997\n",
      "46     also            2036\n",
      "47     has             2038\n",
      "48     a               1037\n",
      "49     red             2417\n",
      "50     light           2422\n",
      "51     on              2006\n",
      "52     top             2327\n",
      "53     ,               1010\n",
      "54     which           2029\n",
      "55     is              2003\n",
      "56     likely          3497\n",
      "57     an              2019\n",
      "58     indicator       17245\n",
      "59     for             2005\n",
      "60     an              2019\n",
      "61     alarm           8598\n",
      "62     or              2030\n",
      "63     warning         5432\n",
      "64     system          2291\n",
      "65     .               1012\n",
      "66     to              2000\n",
      "67     the             1996\n",
      "68     right           2157\n",
      "69     ,               1010\n",
      "70     there           2045\n",
      "71     is              2003\n",
      "72     a               1037\n",
      "73     metal           3384\n",
      "74     ladder          10535\n",
      "75     leaning         6729\n",
      "76     against         2114\n",
      "77     the             1996\n",
      "78     wall            2813\n",
      "79     ,               1010\n",
      "80     which           2029\n",
      "81     is              2003\n",
      "82     commonly        4141\n",
      "83     used            2109\n",
      "84     for             2005\n",
      "85     access          3229\n",
      "86     ##ing           2075\n",
      "87     higher          3020\n",
      "88     areas           2752\n",
      "89     ,               1010\n",
      "90     such            2107\n",
      "91     as              2004\n",
      "92     attic           14832\n",
      "93     ##s             2015\n",
      "94     or              2030\n",
      "95     roofs           15753\n",
      "96     .               1012\n",
      "97     the             1996\n",
      "98     setting         4292\n",
      "99     appears         3544\n",
      "100     to              2000\n",
      "101     be              2022\n",
      "102     an              2019\n",
      "103     interior        4592\n",
      "104     space           2686\n",
      "105     ,               1010\n",
      "106     possibly        4298\n",
      "107     a               1037\n",
      "108     utility         9710\n",
      "109     room            2282\n",
      "110     or              2030\n",
      "111     a               1037\n",
      "112     part            2112\n",
      "113     of              1997\n",
      "114     a               1037\n",
      "115     building        2311\n",
      "116     where           2073\n",
      "117     electrical      5992\n",
      "118     systems         3001\n",
      "119     are             2024\n",
      "120     housed          7431\n",
      "121     .               1012\n",
      "122     [SEP]           102 (special token)\n"
     ]
    }
   ],
   "source": [
    "for idx, (token, token_id) in enumerate(zip(\n",
    "    ['[CLS]'] + tokenizer.tokenize(query_list[0]) + ['[SEP]'] + tokenizer.tokenize(caption_list[0]) + ['[SEP]'],\n",
    "    features['input_ids'][0].tolist()\n",
    ")):\n",
    "    if token_id not in [tokenizer.pad_token_id, tokenizer.cls_token_id, tokenizer.sep_token_id]:\n",
    "        print(f\"{idx:2d}     {token:15s} {token_id}\")\n",
    "    else:\n",
    "        print(f\"{idx:2d}     {token:15s} {token_id} (special token)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videollava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
